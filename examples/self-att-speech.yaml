speech-self-att:
  experiment:
    model_file: examples/output/<EXP>.mod
    hyp_file: examples/output/<EXP>.hyp
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    run_for_epochs: 20
    eval_metrics: cer,wer
  train: !TrainingRegimen
    src_format: contvec
    batcher: !SrcBatcher
      batch_size: 5
    corpus_parser: !BilingualCorpusParser
      src_reader: !ContVecReader
        transpose: True
      trg_reader: !PlainTextReader {}
      training_corpus: !BilingualTrainingCorpus
        train_src: examples/data/synth.contvec.npz
        train_trg: examples/data/synth.char
        dev_src: examples/data/synth.contvec.npz
        dev_trg: examples/data/synth.char
    glob:
      dropout: 0.5
      nonlinearity: silu
    model: !DefaultTranslator
      src_embedder: !NoopEmbedder
        emb_dim: 240
      encoder: !TransformerSeqTransducer
        layers: 2
        input_dim: 240
        hidden_dim: 512
        ff_hidden_dim: 512
        downsample_factor: 2
        diagonal_mask_width: ~
        mask_self: True
        ignore_masks: False
        broadcast_masks: False
        plot_attention: examples/output/<EXP>.self-att
        positional_encoding: True
        diag_gauss_mask: 3
      attender: !MlpAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 512
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !MlpSoftmaxDecoder
        layers: 1
        input_dim: 512
        mlp_hidden_dim: 64
        bridge: !NoBridge {}
  decode: !XnmtDecoder
    src_file: examples/data/synth.contvec.npz
  evaluate:
    ref_file: examples/data/synth.char

