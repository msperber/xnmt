# This config file replicates the Listen-Attend-Spell architecture: https://arxiv.org/pdf/1508.01211.pdf
# Compared to the conventional attentional model, we remove input embeddings, instead directly read in a feature vector
# the pyramidal LSTM reduces length of the input sequence by a factor of 2 per layer (except for the first layer).
# Output units should be characters according to the paper.
defaults:
  experiment:
    model_file: examples/output/<EXP>.mod
    hyp_file: examples/output/<EXP>.hyp
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    run_for_epochs: 20
    eval_metrics: cer,wer
  train:
    src_format: contvec
    training_corpus: !BilingualTrainingCorpus
      train_src: examples/data/synth.contvec.npz
      train_trg: examples/data/synth.char
      dev_src: examples/data/synth.contvec.npz
      dev_trg: examples/data/synth.char
    corpus_parser: !BilingualCorpusParser
      src_reader: !ContVecReader
        transpose: True
        feat_skip: 2
      trg_reader: !PlainTextReader {}
    model: !DefaultTranslator
      src_embedder: !NoopEmbedder
        emb_dim: 240
      encoder: !ModularEncoder
        modules:
        - !StridedConvEncoder
          layers: 3
          output_tensor: False
          input_dim: 120
          chn_dim: 3
          num_filters: 32
          batch_norm: True
          stride:
          - !!python/tuple [2,2]
          - !!python/tuple [2,2]
          - !!python/tuple [2,1]
          nonlinearity: relu
        - !NetworkInNetworkBiLSTMEncoder
          layers: 2
          stride: 1
          num_projections: 1
          input_dim: 224
          batch_norm: False
          hidden_dim: 512
          projection_enabled: True
          nonlinearity: relu
        - !LSTMEncoder
          bidirectional: True
          layers: 1
          input_dim: 512
          hidden_dim: 64
      attender: !StandardAttender
        state_dim: 64
        hidden_dim: 64
        input_dim: 64
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 64
      decoder: !MlpSoftmaxDecoder
        layers: 1
        mlp_hidden_dim: 64
        bridge: !CopyBridge {}
  decode:
    src_file: examples/data/synth.contvec.npz
  evaluate:
    ref_file: examples/data/synth.char

speech-full:

